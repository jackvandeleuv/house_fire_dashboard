{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import *\n",
    "import pandas as pd\n",
    "from ratelimiter import RateLimiter\n",
    "import ast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize city names\n",
    "\n",
    "Use the Google Maps API to standardize place names in our existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 40 calls per second\n",
    "@RateLimiter(max_calls=40, period=1) \n",
    "def get_city_data(city: str, state: str, api_key: str) -> Tuple[float, float]:\n",
    "    city = city.replace(\" \", \"+\")\n",
    "    state = state.replace(\" \", \"+\")\n",
    "    response = requests.get(f\"https://maps.googleapis.com/maps/api/geocode/json?address={city},{state}&key={api_key}\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        results = []\n",
    "        if data['results']:\n",
    "            for result in data['results']:\n",
    "                row = (\n",
    "                    result['geometry']['location']['lat'],\n",
    "                    result['geometry']['location']['lng'],\n",
    "                    result['address_components'],\n",
    "                    result['formatted_address'],\n",
    "                    result['place_id'],\n",
    "                    result['types']\n",
    "                )\n",
    "                results.append(row)\n",
    "            return results\n",
    "    else:\n",
    "        print(\"Request failed with status code:\", response.status_code)\n",
    "        print(response.text)\n",
    "    return None, None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code REAC public inspection data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "reac_13_18 = pd.read_csv('../data/processed/reac_13-18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cities = [x.split(',') for x in reac_13_18.CITYSTATE.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cities_chunk2 = unique_cities[4008:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make ~8000 calls to the Google Maps API. (Took ~25 minutes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# for row in unique_cities:\n",
    "#     results.append((row[0] + ',' + row[1], get_city_data(row[0], row[1], api_key)))\n",
    "\n",
    "# results2 = []\n",
    "# for row in unique_cities_chunk2:\n",
    "#     results2.append((row[0] + ',' + row[1], get_city_data(row[0], row[1], api_key)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package the result into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows = []\n",
    "# for result in results2:\n",
    "#     if len(result[1]) == 1:\n",
    "#         # print(list(result[0]) + list(result[1]))\n",
    "#         rows.append([result[0]] + list(result[1][0]))\n",
    "#     if len(result[1]) > 1:\n",
    "#         if result[1][0] == None:\n",
    "#             continue\n",
    "#         for row in result[1]:\n",
    "#             rows.append([result[0]] + list(row))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give meaningful names to the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(rows)\n",
    "# df = df.rename(columns={\n",
    "#     0: 'citystate',\n",
    "#     1: 'latitude',\n",
    "#     2: 'longitude',\n",
    "#     3: 'address_components',\n",
    "#     4: 'formatted_address',\n",
    "#     5: 'place_id',\n",
    "#     6: 'types'\n",
    "# })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process corrected REAC names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dfs back from csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk1 = pd.read_csv('reac_rename_chunk1.csv')\n",
    "chunk2 = pd.read_csv('reac_rename_chunk2.csv')\n",
    "reac = pd.concat([chunk1, chunk2], axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull out the city and state names from the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For some reason, Google Maps Geocoding API fails whenever the city is named \"Canton.\" We'll replace these values manually.\n",
    "* For some reason, Puerto Rico is identified as a country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_locality(address_components: str) -> str:\n",
    "    address_components = ast.literal_eval(address_components)\n",
    "    for dictionary in address_components:\n",
    "        if 'locality' in dictionary['types']:\n",
    "            return dictionary['long_name']\n",
    "        elif 'administrative_area_level_3' in dictionary['types']:\n",
    "            return dictionary['long_name']\n",
    "\n",
    "def get_state_code(address_components: str) -> str:\n",
    "    address_components = ast.literal_eval(address_components)\n",
    "    for dictionary in address_components:\n",
    "        if 'administrative_area_level_1' in dictionary['types']:\n",
    "            return dictionary['short_name']\n",
    "        \n",
    "def fix_puerto_rico(address_components: str, corrected_address: str) -> str:\n",
    "    address_components = ast.literal_eval(address_components)\n",
    "    is_puerto_rico = False\n",
    "    for dictionary in address_components:\n",
    "        if 'country' in dictionary['types'] and dictionary['short_name'] == 'PR':\n",
    "            is_puerto_rico = True\n",
    "    if is_puerto_rico:\n",
    "        for dictionary in address_components:\n",
    "            if 'administrative_area_level_1' in dictionary['types']:\n",
    "                return dictionary['short_name'].upper() + ',PR'\n",
    "    return corrected_address\n",
    "\n",
    "def fix_cantons(citystate: str, corrected_address: str) -> str:\n",
    "    if citystate.split(',')[0] == 'CANTON':\n",
    "        return citystate\n",
    "    return corrected_address\n",
    "\n",
    "ny_fixes = {\n",
    "    'STATEN ISLAND,NY': 'NEW YORK,NY',\n",
    "    'BRONX,NY': 'NEW YORK,NY',\n",
    "    'BROOKLYN,NY': 'NEW YORK,NY',\n",
    "    'QUEENS,NY': 'NEW YORK,NY',\n",
    "    'MANHATTAN,NY': 'NEW YORK,NY'\n",
    "}\n",
    "\n",
    "def fix_new_york(citystate: str, corrected_address: str) -> str:\n",
    "    if citystate in ny_fixes:\n",
    "        return ny_fixes[citystate]\n",
    "    return corrected_address\n",
    "\n",
    "\n",
    "\n",
    "reac['corrected_address'] = reac.address_components.apply(get_locality).str.upper() + \\\n",
    "                            ',' + \\\n",
    "                            reac.address_components.apply(get_state_code).str.upper()\n",
    "reac['corrected_address'] = reac.apply(lambda x: fix_puerto_rico(x['address_components'], x['corrected_address']), axis=1)\n",
    "reac['corrected_address'] = reac.apply(lambda x: fix_cantons(x['citystate'], x['corrected_address']), axis=1)\n",
    "reac['corrected_address'] = reac.apply(lambda x: fix_new_york(x['citystate'], x['corrected_address']), axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some rows which returned a lowest level of granularity different from the 'locality' level. We'll have to deal with each of these separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "types\n",
       "['locality', 'political']                                                      8140\n",
       "['administrative_area_level_3', 'political']                                    262\n",
       "['neighborhood', 'political']                                                   251\n",
       "['administrative_area_level_1', 'political']                                     50\n",
       "['administrative_area_level_2', 'political']                                     34\n",
       "['establishment', 'natural_feature']                                             13\n",
       "['political', 'sublocality', 'sublocality_level_1']                               9\n",
       "['colloquial_area', 'political']                                                  7\n",
       "['political']                                                                     6\n",
       "['route']                                                                         4\n",
       "['country', 'political']                                                          2\n",
       "['establishment', 'park', 'point_of_interest', 'tourist_attraction']              1\n",
       "['establishment', 'point_of_interest', 'subway_station', 'transit_station']       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reac.groupby(by='types').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "reac_fixed = reac[reac.corrected_address.notna()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Were fixed:\n",
    "* ['neighborhood', 'political'] is standardized already, because we also have the locality key\n",
    "* ['administrative_area_level_3', 'political'] contains valid town/village names\n",
    "* ['political', 'sublocality', 'sublocality_level_1'] were handled individually\n",
    "* ['political', 'sublocality', 'sublocality_level_1'] was fixed manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "reac_fixed.to_csv('reac_fixed.csv', index=False, sep=',')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code NFIRS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfirs = pd.read_csv('../data/processed/other_nfirs_13_18.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strip off blank characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfirs['CITYSTATE'] = nfirs.CITYSTATE.apply(\n",
    "    lambda x: x.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfirs_sub = nfirs[\n",
    "    (~nfirs.CITYSTATE.isin(reac_fixed.citystate)) &\n",
    "    (~nfirs.CITYSTATE.isin(reac_fixed.corrected_address)) &\n",
    "    (nfirs.SUPPORT > 100)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfirs_locs = nfirs_sub.CITYSTATE.unique()\n",
    "nfirs_split = []\n",
    "for loc in nfirs_locs:\n",
    "    nfirs_split.append(loc.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results3 = []\n",
    "# for row in nfirs_split:\n",
    "#     results3.append((row[0] + ',' + row[1], get_city_data(row[0], row[1], api_key)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows3 = []\n",
    "# for result in results3:\n",
    "#     if len(result[1]) == 1:\n",
    "#         # print(list(result[0]) + list(result[1]))\n",
    "#         rows3.append([result[0]] + list(result[1][0]))\n",
    "#     if len(result[1]) > 1:\n",
    "#         if result[1][0] == None:\n",
    "#             continue\n",
    "#         for row in result[1]:\n",
    "#             rows3.append([result[0]] + list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nfirs_api = pd.DataFrame(rows3)\n",
    "# nfirs_api = nfirs_api.rename(columns={\n",
    "#     0: 'citystate',\n",
    "#     1: 'latitude',\n",
    "#     2: 'longitude',\n",
    "#     3: 'address_components',\n",
    "#     4: 'formatted_address',\n",
    "#     5: 'place_id',\n",
    "#     6: 'types'\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nfirs_api.to_csv('nfirs_api.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfirs_api = pd.read_csv('nfirs_api.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_locality(address_components: str) -> str:\n",
    "    address_components = ast.literal_eval(address_components)\n",
    "    for dictionary in address_components:\n",
    "        if 'locality' in dictionary['types']:\n",
    "            return dictionary['long_name']\n",
    "        elif 'administrative_area_level_3' in dictionary['types']:\n",
    "            return dictionary['long_name']\n",
    "\n",
    "def get_state_code(address_components: str) -> str:\n",
    "    address_components = ast.literal_eval(address_components)\n",
    "    for dictionary in address_components:\n",
    "        if 'administrative_area_level_1' in dictionary['types']:\n",
    "            return dictionary['short_name']\n",
    "        \n",
    "def fix_puerto_rico(address_components: str, corrected_address: str) -> str:\n",
    "    address_components = ast.literal_eval(address_components)\n",
    "    is_puerto_rico = False\n",
    "    for dictionary in address_components:\n",
    "        if 'country' in dictionary['types'] and dictionary['short_name'] == 'PR':\n",
    "            is_puerto_rico = True\n",
    "    if is_puerto_rico:\n",
    "        for dictionary in address_components:\n",
    "            if 'administrative_area_level_1' in dictionary['types']:\n",
    "                return dictionary['short_name'].upper() + ',PR'\n",
    "    return corrected_address\n",
    "\n",
    "def fix_cantons(citystate: str, corrected_address: str) -> str:\n",
    "    if citystate.split(',')[0] == 'CANTON':\n",
    "        return citystate\n",
    "    return corrected_address\n",
    "\n",
    "ny_fixes = {\n",
    "    'STATEN ISLAND,NY': 'NEW YORK,NY',\n",
    "    'BRONX,NY': 'NEW YORK,NY',\n",
    "    'BROOKLYN,NY': 'NEW YORK,NY',\n",
    "    'QUEENS,NY': 'NEW YORK,NY',\n",
    "    'MANHATTAN,NY': 'NEW YORK,NY'\n",
    "}\n",
    "\n",
    "def fix_new_york(citystate: str, corrected_address: str) -> str:\n",
    "    if citystate in ny_fixes:\n",
    "        return ny_fixes[citystate]\n",
    "    return corrected_address\n",
    "\n",
    "\n",
    "nfirs_api['corrected_address'] = nfirs_api.address_components.apply(get_locality).str.upper() + \\\n",
    "                                ',' + \\\n",
    "                                nfirs_api.address_components.apply(get_state_code).str.upper()\n",
    "nfirs_api['corrected_address'] = nfirs_api.apply(lambda x: fix_puerto_rico(x['address_components'], x['corrected_address']), axis=1)\n",
    "nfirs_api['corrected_address'] = nfirs_api.apply(lambda x: fix_cantons(x['citystate'], x['corrected_address']), axis=1)\n",
    "nfirs_api['corrected_address'] = nfirs_api.apply(lambda x: fix_new_york(x['citystate'], x['corrected_address']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10967 entries, 0 to 10966\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   citystate           10967 non-null  object \n",
      " 1   latitude            10967 non-null  float64\n",
      " 2   longitude           10967 non-null  float64\n",
      " 3   address_components  10967 non-null  object \n",
      " 4   formatted_address   10967 non-null  object \n",
      " 5   place_id            10967 non-null  object \n",
      " 6   types               10967 non-null  object \n",
      " 7   corrected_address   10476 non-null  object \n",
      "dtypes: float64(2), object(6)\n",
      "memory usage: 685.6+ KB\n"
     ]
    }
   ],
   "source": [
    "nfirs_api.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfirs_api.to_csv('nfirs_fixed.csv', sep=',', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code NSPIRE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nspire = pd.read_csv('../data/nspire_demo_deficiencies.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nspire = nspire[nspire['Shipping City'].notna()]\n",
    "nspire = nspire[nspire['Shipping State/Province'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nspire['Shipping City'] = nspire['Shipping City'].apply(lambda x: x.strip())\n",
    "nspire['Shipping State/Province'] = nspire['Shipping State/Province'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nspire['citystate'] = nspire['Shipping City'].str.upper() + ',' + nspire['Shipping State/Province'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nspire_locs = nspire.citystate.unique()\n",
    "nspire_split = []\n",
    "for loc in nspire_locs:\n",
    "    nspire_split.append(loc.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results4 = []\n",
    "# for row in nspire_split:\n",
    "#     results4.append((row[0] + ',' + row[1], get_city_data(row[0], row[1], api_key)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows4 = []\n",
    "# for result in results4:\n",
    "#     if len(result[1]) == 1:\n",
    "#         # print(list(result[0]) + list(result[1]))\n",
    "#         rows4.append([result[0]] + list(result[1][0]))\n",
    "#     if len(result[1]) > 1:\n",
    "#         if result[1][0] == None:\n",
    "#             continue\n",
    "#         for row in result[1]:\n",
    "#             rows4.append([result[0]] + list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nspire_api = pd.DataFrame(rows4)\n",
    "# nspire_api = nspire_api.rename(columns={\n",
    "#     0: 'citystate',\n",
    "#     1: 'latitude',\n",
    "#     2: 'longitude',\n",
    "#     3: 'address_components',\n",
    "#     4: 'formatted_address',\n",
    "#     5: 'place_id',\n",
    "#     6: 'types'\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nspire_api = pd.read_csv('test_nspire_api.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_locality(address_components: str) -> str:\n",
    "    address_components = ast.literal_eval(address_components)\n",
    "    for dictionary in address_components:\n",
    "        if 'locality' in dictionary['types']:\n",
    "            return dictionary['long_name']\n",
    "        elif 'administrative_area_level_3' in dictionary['types']:\n",
    "            return dictionary['long_name']\n",
    "\n",
    "def get_state_code(address_components: str) -> str:\n",
    "    address_components = ast.literal_eval(address_components)\n",
    "    for dictionary in address_components:\n",
    "        if 'administrative_area_level_1' in dictionary['types']:\n",
    "            return dictionary['short_name']\n",
    "        \n",
    "def fix_puerto_rico(address_components: str, corrected_address: str) -> str:\n",
    "    address_components = ast.literal_eval(address_components)\n",
    "    is_puerto_rico = False\n",
    "    for dictionary in address_components:\n",
    "        if 'country' in dictionary['types'] and dictionary['short_name'] == 'PR':\n",
    "            is_puerto_rico = True\n",
    "    if is_puerto_rico:\n",
    "        for dictionary in address_components:\n",
    "            if 'administrative_area_level_1' in dictionary['types']:\n",
    "                return dictionary['short_name'].upper() + ',PR'\n",
    "    return corrected_address\n",
    "\n",
    "def fix_cantons(citystate: str, corrected_address: str) -> str:\n",
    "    if citystate.split(',')[0] == 'CANTON':\n",
    "        return citystate\n",
    "    return corrected_address\n",
    "\n",
    "ny_fixes = {\n",
    "    'STATEN ISLAND,NY': 'NEW YORK,NY',\n",
    "    'BRONX,NY': 'NEW YORK,NY',\n",
    "    'BROOKLYN,NY': 'NEW YORK,NY',\n",
    "    'QUEENS,NY': 'NEW YORK,NY',\n",
    "    'MANHATTAN,NY': 'NEW YORK,NY'\n",
    "}\n",
    "\n",
    "def fix_new_york(citystate: str, corrected_address: str) -> str:\n",
    "    if citystate in ny_fixes:\n",
    "        return ny_fixes[citystate]\n",
    "    return corrected_address\n",
    "\n",
    "\n",
    "nspire_api['corrected_address'] = nspire_api.address_components.apply(get_locality).str.upper() + \\\n",
    "                                ',' + \\\n",
    "                                nspire_api.address_components.apply(get_state_code).str.upper()\n",
    "nspire_api['corrected_address'] = nspire_api.apply(lambda x: fix_puerto_rico(x['address_components'], x['corrected_address']), axis=1)\n",
    "nspire_api['corrected_address'] = nspire_api.apply(lambda x: fix_cantons(x['citystate'], x['corrected_address']), axis=1)\n",
    "nspire_api['corrected_address'] = nspire_api.apply(lambda x: fix_new_york(x['citystate'], x['corrected_address']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nspire_api.to_csv('nspire_fixed.csv', sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
