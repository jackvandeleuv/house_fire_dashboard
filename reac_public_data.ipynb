{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore public HUD REAC data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Jack Vandeleuv\n",
    "\n",
    "Data files:\n",
    "* [Public Housing Physical Inspection Scores (2016-2021)](https://www.huduser.gov/portal/datasets/pis.html#2021_data-collapse)\n",
    "* [Multifamily Physical Inspection Scores (2016-2021)](https://www.huduser.gov/portal/datasets/pis.html#2021_data-collapse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will explore the publicly released scores from the U.S. Department of Housing and Urban Development's Real Estate Assessment Center (HUD REAC). These scores are derived from physical inspections on HUD properties."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to aggregate REAC data on a city-by-city basis, so we'll focus on data relevant to that analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 538"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place the data files in the data directory and load into pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = 'D:/Fire Project/data/'\n",
    "MULTIFAMILY_FILES = [\n",
    "    'multifamily_physical_inspection_scores_0321.xlsx',\n",
    "    'multifamily_physical_inspection_scores_0620.xlsx',\n",
    "    'multifamily-physical-inspection-scores-2016.xlsx',\n",
    "    'multifamily-physical-inspection-scores-2018.xlsx',\n",
    "    'multifamily-physical-inspection-scores-2019.xlsx'\n",
    "]\n",
    "\n",
    "PUBLIC_HOUSING_FILES = [\n",
    "    'public_housing_physical_inspection_scores_0321.xlsx',\n",
    "    'public_housing_physical_inspection_scores_0620.xlsx',\n",
    "    'public-housing-physical-inspection-scores-2016.xlsx',\n",
    "    'public-housing-physical-inspection-scores-2018.xlsx',\n",
    "    'public-housing-physical-inspection-scores-2019.xlsx'\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zipcode columns is alternately named ZIP and ZIPCODE. We'll rename all columns labeled ZIPCODE as ZIP for consistency sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/public_housing_physical_inspection_scores_0321.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m public_dfs \u001b[39m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i, public_file \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(PUBLIC_HOUSING_FILES):\n\u001b[1;32m----> 5\u001b[0m     public_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_excel(WORKING_DIR \u001b[39m+\u001b[39;49m public_file)\n\u001b[0;32m      6\u001b[0m     multi_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(WORKING_DIR \u001b[39m+\u001b[39m MULTIFAMILY_FILES[i])\n\u001b[0;32m      8\u001b[0m     public_df \u001b[39m=\u001b[39m public_df\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mZIPCODE\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mZIP\u001b[39m\u001b[39m'\u001b[39m}, )\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:482\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    481\u001b[0m     should_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 482\u001b[0m     io \u001b[39m=\u001b[39m ExcelFile(io, storage_options\u001b[39m=\u001b[39;49mstorage_options, engine\u001b[39m=\u001b[39;49mengine)\n\u001b[0;32m    483\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39mand\u001b[39;00m engine \u001b[39m!=\u001b[39m io\u001b[39m.\u001b[39mengine:\n\u001b[0;32m    484\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    485\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    486\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1652\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1650\u001b[0m     ext \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxls\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1651\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1652\u001b[0m     ext \u001b[39m=\u001b[39m inspect_excel_format(\n\u001b[0;32m   1653\u001b[0m         content_or_path\u001b[39m=\u001b[39;49mpath_or_buffer, storage_options\u001b[39m=\u001b[39;49mstorage_options\n\u001b[0;32m   1654\u001b[0m     )\n\u001b[0;32m   1655\u001b[0m     \u001b[39mif\u001b[39;00m ext \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1656\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1657\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExcel file format cannot be determined, you must specify \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1658\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39man engine manually.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1659\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1525\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(content_or_path, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m   1523\u001b[0m     content_or_path \u001b[39m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1525\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m   1526\u001b[0m     content_or_path, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m, storage_options\u001b[39m=\u001b[39;49mstorage_options, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m   1527\u001b[0m ) \u001b[39mas\u001b[39;00m handle:\n\u001b[0;32m   1528\u001b[0m     stream \u001b[39m=\u001b[39m handle\u001b[39m.\u001b[39mhandle\n\u001b[0;32m   1529\u001b[0m     stream\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[0;32m    866\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[0;32m    868\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/public_housing_physical_inspection_scores_0321.xlsx'"
     ]
    }
   ],
   "source": [
    "multi_dfs = []\n",
    "public_dfs = []\n",
    "\n",
    "for i, public_file in enumerate(PUBLIC_HOUSING_FILES):\n",
    "    public_df = pd.read_excel(WORKING_DIR + public_file)\n",
    "    multi_df = pd.read_excel(WORKING_DIR + MULTIFAMILY_FILES[i])\n",
    "\n",
    "    public_df = public_df.rename(columns={'ZIPCODE': 'ZIP'}, )\n",
    "    multi_df = multi_df.rename(columns={'ZIPCODE': 'ZIP'})\n",
    "\n",
    "    public_dfs.append(public_df)\n",
    "    multi_dfs.append(multi_df)\n",
    "\n",
    "multi = pd.concat(multi_dfs, axis=0)\n",
    "public = pd.concat(public_dfs, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the REAC dataset shows the latest inspection for each property, and we're merging data from multiple years, there will be a significant number of duplicates. We'll drop these. We'll define a duplicate as two inspections with the same INSPECTION_ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = multi[~multi.INSPECTION_ID.duplicated()]\n",
    "public = public[~public.INSPECTION_ID.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 63807 entries, 0 to 27876\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   INSPECTION_ID     63807 non-null  int64  \n",
      " 1   PROPERTY_ID       63807 non-null  int64  \n",
      " 2   PROPERTY_NAME     63807 non-null  object \n",
      " 3   ADDRESS           62624 non-null  object \n",
      " 4   CITY              63807 non-null  object \n",
      " 5   CBSA_NAME         58603 non-null  object \n",
      " 6   CBSA_CODE         63777 non-null  float64\n",
      " 7   COUNTY_NAME       63780 non-null  object \n",
      " 8   COUNTY_CODE       63781 non-null  float64\n",
      " 9   STATE_NAME        52362 non-null  object \n",
      " 10  STATE_CODE        63807 non-null  object \n",
      " 11  ZIP               63787 non-null  float64\n",
      " 12  LATITUDE          63781 non-null  float64\n",
      " 13  LONGITUDE         63781 non-null  float64\n",
      " 14  LOCATION_QUALITY  63781 non-null  object \n",
      " 15  INSPECTION_SCORE  63807 non-null  int64  \n",
      " 16  INSPECTION_DATE   63807 non-null  object \n",
      " 17  FIPS_STATE_CODE   11445 non-null  float64\n",
      "dtypes: float64(6), int64(3), object(9)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "multi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16962 entries, 0 to 6778\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   INSPECTION_ID     16962 non-null  int64  \n",
      " 1   DEVELOPMENT_ID    16962 non-null  object \n",
      " 2   DEVELOPMENT_NAME  16962 non-null  object \n",
      " 3   ADDRESS           6639 non-null   object \n",
      " 4   CITY              16962 non-null  object \n",
      " 5   CBSA_NAME         14634 non-null  object \n",
      " 6   CBSA_CODE         16956 non-null  float64\n",
      " 7   COUNTY_NAME       16956 non-null  object \n",
      " 8   COUNTY_CODE       16956 non-null  float64\n",
      " 9   STATE_NAME        13420 non-null  object \n",
      " 10  STATE_CODE        16958 non-null  object \n",
      " 11  ZIP               16960 non-null  float64\n",
      " 12  LATITUDE          16956 non-null  float64\n",
      " 13  LONGITUDE         16956 non-null  float64\n",
      " 14  LOCATION_QUALITY  16960 non-null  object \n",
      " 15  PHA_CODE          16962 non-null  object \n",
      " 16  PHA_NAME          16962 non-null  object \n",
      " 17  INSPECTION_SCORE  16962 non-null  int64  \n",
      " 18  INSPECTION_DATE   16962 non-null  object \n",
      " 19  ADDRESS           9954 non-null   object \n",
      " 20  FIPS_STATE_CODE   3542 non-null   float64\n",
      "dtypes: float64(6), int64(2), object(13)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "public.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at STATE_NAME and STATE_CODE, which has a lot of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE_NAME</th>\n",
       "      <th>STATE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7548</th>\n",
       "      <td>WV</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16258</th>\n",
       "      <td>GA</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>VA</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22460</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4033</th>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      STATE_NAME STATE_CODE\n",
       "7548          WV         54\n",
       "16258         GA         13\n",
       "3573          VA         51\n",
       "22460        NaN         MA\n",
       "4033          AL          1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.sample(n=5, random_state=seed).loc[:, ['STATE_NAME', 'STATE_CODE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE_NAME</th>\n",
       "      <th>STATE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4103</th>\n",
       "      <td>MD</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>VA</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6652</th>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     STATE_NAME STATE_CODE\n",
       "4103         MD         24\n",
       "3385        NaN         IN\n",
       "615          AL          1\n",
       "3059         VA       51.0\n",
       "6652        NaN         VA"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public.sample(n=5, random_state=seed).loc[:, ['STATE_NAME', 'STATE_CODE']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have two different state code formats. We'll combine these into a single column with only the two-letter state codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_columns(row):\n",
    "    if pd.isnull(row['STATE_NAME']):\n",
    "        return row['STATE_CODE']\n",
    "    else:\n",
    "        return row['STATE_NAME']\n",
    "\n",
    "public['STATE'] = public.apply(combine_columns, axis=1)\n",
    "multi['STATE'] = multi.apply(combine_columns, axis=1)\n",
    "\n",
    "public = public.drop(columns=['STATE_NAME', 'STATE_CODE'])\n",
    "multi = multi.drop(columns=['STATE_NAME', 'STATE_CODE'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look again to see what nulls are left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16962 entries, 0 to 6778\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   INSPECTION_ID     16962 non-null  int64  \n",
      " 1   DEVELOPMENT_ID    16962 non-null  object \n",
      " 2   DEVELOPMENT_NAME  16962 non-null  object \n",
      " 3   ADDRESS           6639 non-null   object \n",
      " 4   CITY              16962 non-null  object \n",
      " 5   CBSA_NAME         14634 non-null  object \n",
      " 6   CBSA_CODE         16956 non-null  float64\n",
      " 7   COUNTY_NAME       16956 non-null  object \n",
      " 8   COUNTY_CODE       16956 non-null  float64\n",
      " 9   ZIP               16960 non-null  float64\n",
      " 10  LATITUDE          16956 non-null  float64\n",
      " 11  LONGITUDE         16956 non-null  float64\n",
      " 12  LOCATION_QUALITY  16960 non-null  object \n",
      " 13  PHA_CODE          16962 non-null  object \n",
      " 14  PHA_NAME          16962 non-null  object \n",
      " 15  INSPECTION_SCORE  16962 non-null  int64  \n",
      " 16  INSPECTION_DATE   16962 non-null  object \n",
      " 17  ADDRESS           9954 non-null   object \n",
      " 18  FIPS_STATE_CODE   3542 non-null   float64\n",
      " 19  STATE             16962 non-null  object \n",
      "dtypes: float64(6), int64(2), object(12)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "public.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 63807 entries, 0 to 27876\n",
      "Data columns (total 17 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   INSPECTION_ID     63807 non-null  int64  \n",
      " 1   PROPERTY_ID       63807 non-null  int64  \n",
      " 2   PROPERTY_NAME     63807 non-null  object \n",
      " 3   ADDRESS           62624 non-null  object \n",
      " 4   CITY              63807 non-null  object \n",
      " 5   CBSA_NAME         58603 non-null  object \n",
      " 6   CBSA_CODE         63777 non-null  float64\n",
      " 7   COUNTY_NAME       63780 non-null  object \n",
      " 8   COUNTY_CODE       63781 non-null  float64\n",
      " 9   ZIP               63787 non-null  float64\n",
      " 10  LATITUDE          63781 non-null  float64\n",
      " 11  LONGITUDE         63781 non-null  float64\n",
      " 12  LOCATION_QUALITY  63781 non-null  object \n",
      " 13  INSPECTION_SCORE  63807 non-null  int64  \n",
      " 14  INSPECTION_DATE   63807 non-null  object \n",
      " 15  FIPS_STATE_CODE   11445 non-null  float64\n",
      " 16  STATE             63807 non-null  object \n",
      "dtypes: float64(6), int64(3), object(8)\n",
      "memory usage: 8.8+ MB\n"
     ]
    }
   ],
   "source": [
    "multi.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have no nulls in CITY and STATE. Let's look at the remaining nulls in ZIP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Unique states represented among null zipcodes: ['PR']\n"
     ]
    }
   ],
   "source": [
    "print(len(public[public.ZIP.isna()]))\n",
    "print('Unique states represented among null zipcodes:', public[public.ZIP.isna()].STATE.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Unique states represented among null zipcodes: ['MA' 'PR' 'NJ' 'VA' 'GA' 'WY' 'TN' 'OH' 'CA' 'DC' 'UT']\n"
     ]
    }
   ],
   "source": [
    "print(len(multi[multi.ZIP.isna()]))\n",
    "print('Unique states represented among null zipcodes:', multi[multi.ZIP.isna()].STATE.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the city names to be upper-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi.CITY = multi.CITY.str.upper()\n",
    "public.CITY = public.CITY.str.upper()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a small number of inspection without zipcode data. We'll leave these for now, and see if we can perform the spatial join without the zipcode data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll convert the datetimes to a standard format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public['INSPECTION_DATE'] = pd.to_datetime(public['INSPECTION_DATE'], infer_datetime_format=True)\n",
    "multi['INSPECTION_DATE'] = pd.to_datetime(multi['INSPECTION_DATE'], infer_datetime_format=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to see if we have any cities in the same state with the same name. We'll check this using latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_citystate = multi.loc[:, ['CITY', 'STATE']]\n",
    "multi_unique_locs = multi_citystate[~multi_citystate.duplicated()].values.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at this distribution of scores by date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INSPECTION_DATE\n",
       "2013     2949\n",
       "2014     8542\n",
       "2015    10762\n",
       "2016     9104\n",
       "2017     7471\n",
       "2018    11856\n",
       "2019    11286\n",
       "2020     1835\n",
       "2021        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.groupby(by=multi.INSPECTION_DATE.dt.year).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'public' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m public\u001b[39m.\u001b[39mgroupby(by\u001b[39m=\u001b[39mpublic\u001b[39m.\u001b[39mINSPECTION_DATE\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39myear)\u001b[39m.\u001b[39msize()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'public' is not defined"
     ]
    }
   ],
   "source": [
    "public.groupby(by=public.INSPECTION_DATE.dt.year).size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bulk of inspections in the dataset occurred between 2013 and 2020, with a drop-off when the 2019 pandemic started. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll export our cleaned data from before 2019. (We'll reserve the remainder as a validation set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m multi\n",
      "\u001b[1;31mNameError\u001b[0m: name 'multi' is not defined"
     ]
    }
   ],
   "source": [
    "multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi.to_csv('data/clean_agg_multi.csv', \n",
    "             sep=',', \n",
    "             index=False)\n",
    "public.to_csv('data/clean_agg_public.csv', \n",
    "              sep=',',\n",
    "              index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: there are a few values that have mismatch between coordinates and the listed address, or that are an outlier in terms of min/max latitude/longitude. We can remove these, although there are likely not too many values.\n",
    "\n",
    "In general, a spread-out city like KCMO might vary by about 1 latitude point from top to bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_lats = []\n",
    "# max_longs = []\n",
    "\n",
    "# for city, state in multi_unique_locs:\n",
    "#     city_mask = multi.CITY == city\n",
    "#     state_mask = multi.STATE == state\n",
    "#     multi_sub = multi[city_mask & state_mask]\n",
    "#     max_lats.append((city, state, multi_sub.LATITUDE.max() - multi_sub.LATITUDE.min()))\n",
    "#     max_longs.append((city, state, multi_sub.LONGITUDE.max() - multi_sub.LONGITUDE.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(max_lats, key=lambda x: x[2], reverse=True)[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top value has an incorrect latitude and longitude, but the address is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_mask = multi.CITY == 'WINCHESTER'\n",
    "# state_mask = multi.STATE == 'VA'\n",
    "\n",
    "# multi[city_mask & state_mask].sort_values(by='LATITUDE')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top value is miscoded as being in Hamilton Township when it's not, which results in a high latitude rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_mask = multi.CITY == 'HAMILTON TOWNSHIP'\n",
    "# state_mask = multi.STATE == 'NJ'\n",
    "\n",
    "# multi[city_mask & state_mask].sort_values(by='LATITUDE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(max_longs, key=lambda x: x[2], reverse=True)[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
