{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore public HUD REAC data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Jack Vandeleuv\n",
    "\n",
    "Data files:\n",
    "* [Public Housing Physical Inspection Scores (2016-2021)](https://www.huduser.gov/portal/datasets/pis.html#2021_data-collapse)\n",
    "* [Multifamily Physical Inspection Scores (2016-2021)](https://www.huduser.gov/portal/datasets/pis.html#2021_data-collapse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will explore the publicly released scores from the U.S. Department of Housing and Urban Development's Real Estate Assessment Center (HUD REAC). These scores are derived from physical inspections on HUD properties."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to aggregate REAC data on a city-by-city basis, so we'll focus on data relevant to that analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 538"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place the data files in the data directory and load into pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIRECTORY_IN = 'D:/Fire Project/data/raw/reac/'\n",
    "MULTIFAMILY_FILES = [\n",
    "    'multifamily_physical_inspection_scores_0321.xlsx',\n",
    "    'multifamily_physical_inspection_scores_0620.xlsx',\n",
    "    'multifamily-physical-inspection-scores-2016.xlsx',\n",
    "    'multifamily-physical-inspection-scores-2018.xlsx',\n",
    "    'multifamily-physical-inspection-scores-2019.xlsx'\n",
    "]\n",
    "\n",
    "PUBLIC_HOUSING_FILES = [\n",
    "    'public_housing_physical_inspection_scores_0321.xlsx',\n",
    "    'public_housing_physical_inspection_scores_0620.xlsx',\n",
    "    'public-housing-physical-inspection-scores-2016.xlsx',\n",
    "    'public-housing-physical-inspection-scores-2018.xlsx',\n",
    "    'public-housing-physical-inspection-scores-2019.xlsx'\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zipcode columns is alternately named ZIP and ZIPCODE. We'll rename all columns labeled ZIPCODE as ZIP for consistency sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_files = [\n",
    "    pd.read_excel(WORKING_DIRECTORY_IN + file)\n",
    "    .rename(columns={'ZIPCODE': 'ZIP'})\n",
    "    for file in PUBLIC_HOUSING_FILES\n",
    "]\n",
    "\n",
    "multi_files = [\n",
    "    pd.read_excel(WORKING_DIRECTORY_IN + file)\n",
    "    .rename(columns={'ZIPCODE': 'ZIP'})\n",
    "    for file in MULTIFAMILY_FILES\n",
    "]\n",
    "\n",
    "public = pd.concat(public_files, axis=0)\n",
    "multi = pd.concat(multi_files, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the REAC dataset shows the latest inspection for each property, and we're merging data from multiple years, there will be a significant number of duplicates. We'll drop these. We'll define a duplicate as two inspections with the same INSPECTION_ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = multi.drop_duplicates(subset='INSPECTION_ID')\n",
    "public = public.drop_duplicates(subset='INSPECTION_ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 63807 entries, 0 to 27876\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   INSPECTION_ID     63807 non-null  int64  \n",
      " 1   PROPERTY_ID       63807 non-null  int64  \n",
      " 2   PROPERTY_NAME     63807 non-null  object \n",
      " 3   ADDRESS           62624 non-null  object \n",
      " 4   CITY              63807 non-null  object \n",
      " 5   CBSA_NAME         58603 non-null  object \n",
      " 6   CBSA_CODE         63777 non-null  float64\n",
      " 7   COUNTY_NAME       63780 non-null  object \n",
      " 8   COUNTY_CODE       63781 non-null  float64\n",
      " 9   STATE_NAME        52362 non-null  object \n",
      " 10  STATE_CODE        63807 non-null  object \n",
      " 11  ZIP               63787 non-null  float64\n",
      " 12  LATITUDE          63781 non-null  float64\n",
      " 13  LONGITUDE         63781 non-null  float64\n",
      " 14  LOCATION_QUALITY  63781 non-null  object \n",
      " 15  INSPECTION_SCORE  63807 non-null  int64  \n",
      " 16  INSPECTION_DATE   63807 non-null  object \n",
      " 17  FIPS_STATE_CODE   11445 non-null  float64\n",
      "dtypes: float64(6), int64(3), object(9)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "multi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16962 entries, 0 to 6778\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   INSPECTION_ID     16962 non-null  int64  \n",
      " 1   DEVELOPMENT_ID    16962 non-null  object \n",
      " 2   DEVELOPMENT_NAME  16962 non-null  object \n",
      " 3   ADDRESS           6639 non-null   object \n",
      " 4   CITY              16962 non-null  object \n",
      " 5   CBSA_NAME         14634 non-null  object \n",
      " 6   CBSA_CODE         16956 non-null  float64\n",
      " 7   COUNTY_NAME       16956 non-null  object \n",
      " 8   COUNTY_CODE       16956 non-null  float64\n",
      " 9   STATE_NAME        13420 non-null  object \n",
      " 10  STATE_CODE        16958 non-null  object \n",
      " 11  ZIP               16960 non-null  float64\n",
      " 12  LATITUDE          16956 non-null  float64\n",
      " 13  LONGITUDE         16956 non-null  float64\n",
      " 14  LOCATION_QUALITY  16960 non-null  object \n",
      " 15  PHA_CODE          16962 non-null  object \n",
      " 16  PHA_NAME          16962 non-null  object \n",
      " 17  INSPECTION_SCORE  16962 non-null  int64  \n",
      " 18  INSPECTION_DATE   16962 non-null  object \n",
      " 19  ADDRESS           9954 non-null   object \n",
      " 20  FIPS_STATE_CODE   3542 non-null   float64\n",
      "dtypes: float64(6), int64(2), object(13)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "public.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at STATE_NAME and STATE_CODE, which has a lot of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE_NAME</th>\n",
       "      <th>STATE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7548</th>\n",
       "      <td>WV</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16258</th>\n",
       "      <td>GA</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>VA</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22460</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4033</th>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      STATE_NAME STATE_CODE\n",
       "7548          WV         54\n",
       "16258         GA         13\n",
       "3573          VA         51\n",
       "22460        NaN         MA\n",
       "4033          AL          1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.sample(n=5, random_state=seed).loc[:, ['STATE_NAME', 'STATE_CODE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE_NAME</th>\n",
       "      <th>STATE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4103</th>\n",
       "      <td>MD</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>NaN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>VA</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6652</th>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     STATE_NAME STATE_CODE\n",
       "4103         MD         24\n",
       "3385        NaN         IN\n",
       "615          AL          1\n",
       "3059         VA       51.0\n",
       "6652        NaN         VA"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public.sample(n=5, random_state=seed).loc[:, ['STATE_NAME', 'STATE_CODE']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have two different state code formats. We'll combine these into a single column with only the two-letter state codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_columns(row):\n",
    "    if pd.isnull(row['STATE_NAME']):\n",
    "        return row['STATE_CODE']\n",
    "    else:\n",
    "        return row['STATE_NAME']\n",
    "\n",
    "public['STATE'] = public.apply(combine_columns, axis=1)\n",
    "multi['STATE'] = multi.apply(combine_columns, axis=1)\n",
    "\n",
    "public = public.drop(columns=['STATE_NAME', 'STATE_CODE'])\n",
    "multi = multi.drop(columns=['STATE_NAME', 'STATE_CODE'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look again to see what nulls are left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16962 entries, 0 to 6778\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   INSPECTION_ID     16962 non-null  int64  \n",
      " 1   DEVELOPMENT_ID    16962 non-null  object \n",
      " 2   DEVELOPMENT_NAME  16962 non-null  object \n",
      " 3   ADDRESS           6639 non-null   object \n",
      " 4   CITY              16962 non-null  object \n",
      " 5   CBSA_NAME         14634 non-null  object \n",
      " 6   CBSA_CODE         16956 non-null  float64\n",
      " 7   COUNTY_NAME       16956 non-null  object \n",
      " 8   COUNTY_CODE       16956 non-null  float64\n",
      " 9   ZIP               16960 non-null  float64\n",
      " 10  LATITUDE          16956 non-null  float64\n",
      " 11  LONGITUDE         16956 non-null  float64\n",
      " 12  LOCATION_QUALITY  16960 non-null  object \n",
      " 13  PHA_CODE          16962 non-null  object \n",
      " 14  PHA_NAME          16962 non-null  object \n",
      " 15  INSPECTION_SCORE  16962 non-null  int64  \n",
      " 16  INSPECTION_DATE   16962 non-null  object \n",
      " 17  ADDRESS           9954 non-null   object \n",
      " 18  FIPS_STATE_CODE   3542 non-null   float64\n",
      " 19  STATE             16962 non-null  object \n",
      "dtypes: float64(6), int64(2), object(12)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "public.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 63807 entries, 0 to 27876\n",
      "Data columns (total 17 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   INSPECTION_ID     63807 non-null  int64  \n",
      " 1   PROPERTY_ID       63807 non-null  int64  \n",
      " 2   PROPERTY_NAME     63807 non-null  object \n",
      " 3   ADDRESS           62624 non-null  object \n",
      " 4   CITY              63807 non-null  object \n",
      " 5   CBSA_NAME         58603 non-null  object \n",
      " 6   CBSA_CODE         63777 non-null  float64\n",
      " 7   COUNTY_NAME       63780 non-null  object \n",
      " 8   COUNTY_CODE       63781 non-null  float64\n",
      " 9   ZIP               63787 non-null  float64\n",
      " 10  LATITUDE          63781 non-null  float64\n",
      " 11  LONGITUDE         63781 non-null  float64\n",
      " 12  LOCATION_QUALITY  63781 non-null  object \n",
      " 13  INSPECTION_SCORE  63807 non-null  int64  \n",
      " 14  INSPECTION_DATE   63807 non-null  object \n",
      " 15  FIPS_STATE_CODE   11445 non-null  float64\n",
      " 16  STATE             63807 non-null  object \n",
      "dtypes: float64(6), int64(3), object(8)\n",
      "memory usage: 8.8+ MB\n"
     ]
    }
   ],
   "source": [
    "multi.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have no nulls in CITY and STATE. Let's look at the remaining nulls in ZIP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Unique states represented among null zipcodes: ['PR']\n"
     ]
    }
   ],
   "source": [
    "print(len(public[public.ZIP.isna()]))\n",
    "print('Unique states represented among null zipcodes:', public[public.ZIP.isna()].STATE.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Unique states represented among null zipcodes: ['MA' 'PR' 'NJ' 'VA' 'GA' 'WY' 'TN' 'OH' 'CA' 'DC' 'UT']\n"
     ]
    }
   ],
   "source": [
    "print(len(multi[multi.ZIP.isna()]))\n",
    "print('Unique states represented among null zipcodes:', multi[multi.ZIP.isna()].STATE.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the city names to be upper-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi.CITY = multi.CITY.str.upper()\n",
    "public.CITY = public.CITY.str.upper()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a small number of inspection without zipcode data. We'll leave these for now, and see if we can perform the spatial join without the zipcode data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll convert the datetimes to a standard format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "public['INSPECTION_DATE'] = pd.to_datetime(public['INSPECTION_DATE'], infer_datetime_format=True)\n",
    "multi['INSPECTION_DATE'] = pd.to_datetime(multi['INSPECTION_DATE'], infer_datetime_format=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to see if we have any cities in the same state with the same name. We'll check this using latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_citystate = multi.loc[:, ['CITY', 'STATE']]\n",
    "multi_unique_locs = multi_citystate[~multi_citystate.duplicated()].values.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at this distribution of inspections by date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Multi</th>\n",
       "      <th>Public</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSPECTION_DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2949.0</td>\n",
       "      <td>336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>8542.0</td>\n",
       "      <td>1739.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>10762.0</td>\n",
       "      <td>3272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>9104.0</td>\n",
       "      <td>2424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>7471.0</td>\n",
       "      <td>3302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>11856.0</td>\n",
       "      <td>2438.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>11286.0</td>\n",
       "      <td>2566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>1835.0</td>\n",
       "      <td>879.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Multi  Public\n",
       "INSPECTION_DATE                 \n",
       "2005                 NaN     1.0\n",
       "2012                 NaN     5.0\n",
       "2013              2949.0   336.0\n",
       "2014              8542.0  1739.0\n",
       "2015             10762.0  3272.0\n",
       "2016              9104.0  2424.0\n",
       "2017              7471.0  3302.0\n",
       "2018             11856.0  2438.0\n",
       "2019             11286.0  2566.0\n",
       "2020              1835.0   879.0\n",
       "2021                 2.0     NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multi_grouped = multi.groupby(by=multi.INSPECTION_DATE.dt.year).size()\n",
    "public_grouped = public.groupby(by=public.INSPECTION_DATE.dt.year).size()\n",
    "\n",
    "side_by_side = pd.concat([multi_grouped, public_grouped], axis=1)\n",
    "side_by_side.columns = ['Multi', 'Public']\n",
    "display(side_by_side.sort_index())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bulk of inspections in the dataset occurred between 2013 and 2020, with a drop-off when the 2019 pandemic started. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export our cleaned data from before 2019. (Reserve the remainder as a validation set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_13_19 = multi[\n",
    "    (multi.INSPECTION_DATE.dt.year < 2019) &\n",
    "    (multi.INSPECTION_DATE.dt.year >= 2013)\n",
    "]\n",
    "\n",
    "public_13_19 = public[\n",
    "    (public.INSPECTION_DATE.dt.year < 2019) &\n",
    "    (public.INSPECTION_DATE.dt.year >= 2013)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIRECTORY_OUT = 'D:/Fire Project/data/processed/'\n",
    "\n",
    "multi_13_19.to_csv(\n",
    "    WORKING_DIRECTORY_OUT + 'multi_13-19.csv', \n",
    "    sep=',', \n",
    "    index=False)\n",
    "\n",
    "public_13_19.to_csv(\n",
    "    WORKING_DIRECTORY_OUT + 'public_13-19.csv', \n",
    "    sep=',',\n",
    "    index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
